export const profile = {
  name: 'Seonglae Cho',
  title: 'Research Scientist',
  bio: 'Research scientist focused on LLM safety, interpretability, and steering. Building tools to understand and control language model behavior.',
  photo: '/image/profile.jpg',
  links: {
    scholar: 'https://scholar.google.com/citations?user=YOUR_ID',
    github: 'https://github.com/seonglae',
    linkedin: 'https://linkedin.com/in/seonglae',
    twitter: 'https://twitter.com/seonglaecho',
  },
  interests: [
    'LLM Safety',
    'Mechanistic Interpretability',
    'Sparse Autoencoders',
    'Steering Vectors',
    'Summarization',
  ],
  news: [
    { date: '2026.02', text: 'CRL paper published on arXiv' },
    { date: '2026.02', text: 'Confidence Manifold paper published on arXiv' },
    { date: '2025.08', text: 'CorrSteer paper published on arXiv' },
    { date: '2025', text: 'FaithfulSAE accepted at ACL 2025 SRW' },
    { date: '2025', text: 'LibVulnWatch accepted at ICML 2025 TAIG' },
  ],
}
